{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c432f21d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Perceptrons Brain Dump:\n",
    "\n",
    "TLU: threshold logic unit<br>\n",
    "LTU: linear threshold unit<br>\n",
    "\n",
    "\n",
    "#### **how is a single perceptron trained?** <br>\n",
    "**basic idea:** <br>\n",
    "* when two neurons fire together, the connection bewtween them becomes stronger. <br> \n",
    "* connection weight between two neurons is increased whenever they have the same output. <br>\n",
    "* perceptrons are trained in a similar way by also taking into account the error made by the network. it reinforces the connections that help reduce the error.\n",
    "\n",
    "~~~\n",
    "for each (x, y) in dataset:\n",
    "    z = dot(w, x) + b\n",
    "    y_pred = sign(z)\n",
    "    if y_pred != y:\n",
    "        w = w + η * y * x\n",
    "        b = b + η * y\n",
    "~~~\n",
    "\n",
    "\n",
    "Works only if data is linearly separable. Logistic Regression gives more accurate outputs than a single perceptron.\n",
    "\n",
    "Converges in finite steps if such a solution exists (Perceptron Convergence Theorem).\n",
    "\n",
    "Simple, but doesn't work well on complex tasks (hence, MLPs / neural nets)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb257459",
   "metadata": {},
   "source": [
    "### Implementing from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93b49647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06351295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLU(object):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        self.weights = np.zeros(input_size + 1)\n",
    "\n",
    "    \n",
    "    def activate(self, x):\n",
    "        return 1 if x >= 0 else 0\n",
    "    \n",
    "\n",
    "    def predict(self, row):\n",
    "        # predict individual row in a given dataset\n",
    "        xw = np.array(row).dot(self.weights)\n",
    "        a = self.activate(xw)\n",
    "        return a\n",
    "    \n",
    "\n",
    "    def train_tlu(self, data, targets, epochs, lrate):\n",
    "        for e in range(epochs):\n",
    "            # x row and each target\n",
    "            for row, t in zip(data, targets):\n",
    "                # Adds a bias term to the input row by inserting -1 at the beginning of the row.\n",
    "                row = np.insert(row, 0, -1)\n",
    "                y_pred = self.predict(row)\n",
    "\n",
    "                if y_pred != t:\n",
    "                    error = t - y_pred\n",
    "                    for r in range(len(self.weights)):\n",
    "                        self.weights[r] = self.weights[r] + lrate * error * row[r]\n",
    "\n",
    "                else: continue\n",
    "\n",
    "        return self.weights\n",
    "    \n",
    "\n",
    "def tlu_pred(model, data, targets, epochs, lrate=0.2,):\n",
    "    adj_w = model.train_tlu(data, targets, epochs, lrate)\n",
    "    print(model)\n",
    "    return adj_w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aca9f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logical AND Data:\n",
    "andData = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "andTargets = np.array([0,0,0,1])\n",
    "\n",
    "# Logical OR Data:\n",
    "orData = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "orTargets = np.array([0,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a5c8fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.TLU object at 0x0000021D8FF4D790>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6, 0.6, 0.6])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TLU(input_size=2)\n",
    "tlu_pred(model, orData, orTargets, epochs=11, lrate=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95fca8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad332794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2049380",
   "metadata": {},
   "source": [
    "### Using SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5831e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0486e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a78cf767",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, (2,3)] # only the petal length and petal width\n",
    "y = (iris.target == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ab0f260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Perceptron</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.Perceptron.html\">?<span>Documentation for Perceptron</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Perceptron()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percep = Perceptron()\n",
    "percep.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98049f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = percep.predict([[2, 0.5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631fcb7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18287388",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron\n",
    "\n",
    "### Implementing MLP Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b83df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d715c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationFunction:\n",
    "    \"\"\"Base class for activation functions\"\"\"\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def backward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ReLU(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return np.maximum(0, x)\n",
    "    \n",
    "    def backward(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        # Clip to prevent overflow\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def backward(self, x):\n",
    "        s = self.forward(x)\n",
    "        return s * (1 - s)\n",
    "\n",
    "class Tanh(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return np.tanh(x)\n",
    "    \n",
    "    def backward(self, x):\n",
    "        return 1 - np.tanh(x) ** 2\n",
    "\n",
    "class Linear(ActivationFunction):\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    def backward(self, x):\n",
    "        return np.ones_like(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c945eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \"\"\"A single layer in the neural network\"\"\"\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        # Initialize weights with Xavier initialization\n",
    "        # The core idea is to initialize weights from a normal distribution with a mean of 0 and a\n",
    "        # standard deviation calculated based on the number of incoming (fan-in) and outgoing (fan-out) \n",
    "        # connections to a neuron. # \n",
    "        self.weights = np.random.randn(input_size, output_size) * np.sqrt(2.0 / input_size)\n",
    "        self.biases = np.zeros((1, output_size))\n",
    "        self.activation = activation\n",
    "        \n",
    "        # Store values for backprop\n",
    "        self.last_input = None\n",
    "        self.last_z = None  # Before activation\n",
    "        self.last_a = None  # After  activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through this layer\"\"\"\n",
    "        self.last_input = x.copy()\n",
    "        \n",
    "        # Linear transformation: z = xW + b\n",
    "        self.last_z = np.dot(x, self.weights) + self.biases\n",
    "        \n",
    "        # Apply activation function: a = f(z)\n",
    "        self.last_a = self.activation.forward(self.last_z)\n",
    "        \n",
    "        print(f\"Layer forward:\")\n",
    "        print(f\"  Input shape: {x.shape}\")\n",
    "        print(f\"  Weights shape: {self.weights.shape}\")\n",
    "        print(f\"  Z (before activation): {self.last_z.flatten()[:3]}... (first 3 values)\")\n",
    "        print(f\"  A (after activation): {self.last_a.flatten()[:3]}... (first 3 values)\")\n",
    "        print()\n",
    "        \n",
    "        return self.last_a\n",
    "    \n",
    "    def backward(self, grad_output, learning_rate):\n",
    "        \"\"\"Backward pass through this layer\"\"\"\n",
    "        print(f\"Layer backward:\")\n",
    "        print(f\"  Grad output shape: {grad_output.shape}\")\n",
    "        \n",
    "        # Gradient w.r.t. pre-activation (z): dL/dz = dL/da * da/dz\n",
    "        activation_grad = self.activation.backward(self.last_z)\n",
    "        grad_z = grad_output * activation_grad\n",
    "        \n",
    "        print(f\"  Activation gradient: {activation_grad.flatten()[:3]}... (first 3)\")\n",
    "        print(f\"  Grad z: {grad_z.flatten()[:3]}... (first 3)\")\n",
    "        \n",
    "        # Gradients w.r.t. weights and biases\n",
    "        grad_weights = np.dot(self.last_input.T, grad_z)\n",
    "        grad_biases = np.sum(grad_z, axis=0, keepdims=True)\n",
    "        \n",
    "        # Gradient w.r.t. input (for previous layer): dL/dx = dL/dz * dz/dx = dL/dz * W^T\n",
    "        grad_input = np.dot(grad_z, self.weights.T)\n",
    "        \n",
    "        print(f\"  Grad weights shape: {grad_weights.shape}\")\n",
    "        print(f\"  Grad input: {grad_input.flatten()[:3]}... (first 3)\")\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.weights -= learning_rate * grad_weights\n",
    "        self.biases -= learning_rate * grad_biases\n",
    "        print()\n",
    "        \n",
    "        return grad_input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP:\n",
    "    \"\"\"Multi-Layer Perceptron\"\"\"\n",
    "    def __init__(self, layer_sizes, activations):\n",
    "        self.layers = []\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            input_size = layer_sizes[i]\n",
    "            output_size = layer_sizes[i + 1]\n",
    "            activation = activations[i]\n",
    "            \n",
    "            layer = Layer(input_size, output_size, activation)\n",
    "            self.layers.append(layer)\n",
    "            \n",
    "        print(f\"Created MLP with {len(self.layers)} layers:\")\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"  Layer {i}: {layer.weights.shape[0]} → {layer.weights.shape[1]} ({layer.activation.__class__.__name__})\")\n",
    "        print()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through entire network\"\"\"\n",
    "        print(\"=== FORWARD PASS ===\")\n",
    "        current = x\n",
    "        \n",
    "        for i, layer in enumerate(self.layers):\n",
    "            print(f\"Passing through layer {i}:\")\n",
    "            current = layer.forward(current)\n",
    "            \n",
    "        print(f\"Final output: {current}\")\n",
    "        print()\n",
    "        return current\n",
    "    \n",
    "    def backward(self, y_true, y_pred, learning_rate):\n",
    "        \"\"\"Backward pass through entire network\"\"\"\n",
    "        print(\"=== BACKWARD PASS ===\")\n",
    "        \n",
    "        # Start with loss gradient (for MSE loss)\n",
    "        # L = 2/m * (y_pred - y_i)\n",
    "        loss_grad = (2 / len(y_true)) * (y_pred - y_true) \n",
    "        print(f\"Initial loss gradient: {loss_grad}\")\n",
    "        print()\n",
    "        \n",
    "        current_grad = loss_grad\n",
    "        \n",
    "        # Backpropagate through layers in reverse order\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            print(f\"Backpropagating through layer {i}:\")\n",
    "            current_grad = self.layers[i].backward(current_grad, learning_rate)\n",
    "    \n",
    "    def train_step(self, x, y, learning_rate=0.01):\n",
    "        \"\"\"Single training step\"\"\"\n",
    "        # Forward pass\n",
    "        y_pred = self.forward(x)\n",
    "        \n",
    "        # Calculate loss (MSE)\n",
    "        loss = np.mean((y_pred - y) ** 2)\n",
    "        \n",
    "        # Backward pass\n",
    "        self.backward(y, y_pred, learning_rate)\n",
    "        \n",
    "        return loss, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac28ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a simple dataset...\n",
      "Dataset:\n",
      "X:\n",
      "[[0.37454012 0.95071431]\n",
      " [0.73199394 0.59865848]\n",
      " [0.15601864 0.15599452]\n",
      " [0.05808361 0.86617615]]\n",
      "y: [1. 1. 0. 0.]\n",
      "\n",
      "Created MLP with 2 layers:\n",
      "  Layer 0: 2 → 3 (ReLU)\n",
      "  Layer 1: 3 → 1 (Sigmoid)\n",
      "\n",
      "Training for a few steps...\n",
      "\n",
      "==================================================\n",
      "EPOCH 1\n",
      "==================================================\n",
      "=== FORWARD PASS ===\n",
      "Passing through layer 0:\n",
      "Layer forward:\n",
      "  Input shape: (4, 2)\n",
      "  Weights shape: (2, 3)\n",
      "  Z (before activation): [ 1.10729815 -0.15314274 -0.61861293]... (first 3 values)\n",
      "  A (after activation): [1.10729815 0.         0.        ]... (first 3 values)\n",
      "\n",
      "Passing through layer 1:\n",
      "Layer forward:\n",
      "  Input shape: (4, 3)\n",
      "  Weights shape: (3, 1)\n",
      "  Z (before activation): [ 0.21875934 -0.15162905 -0.00871825]... (first 3 values)\n",
      "  A (after activation): [0.55447277 0.4621652  0.49782045]... (first 3 values)\n",
      "\n",
      "Final output: [[0.55447277]\n",
      " [0.4621652 ]\n",
      " [0.49782045]\n",
      " [0.52771308]]\n",
      "\n",
      "=== BACKWARD PASS ===\n",
      "Initial loss gradient: [[-0.22276361]\n",
      " [-0.2689174 ]\n",
      " [ 0.24891023]\n",
      " [ 0.26385654]]\n",
      "\n",
      "Backpropagating through layer 1:\n",
      "Layer backward:\n",
      "  Grad output shape: (4, 1)\n",
      "  Activation gradient: [0.24703272 0.24856853 0.24999525]... (first 3)\n",
      "  Grad z: [-0.0550299  -0.0668444   0.06222637]... (first 3)\n",
      "  Grad weights shape: (3, 1)\n",
      "  Grad input: [-0.01087178  0.08596698  0.07750354]... (first 3)\n",
      "\n",
      "Backpropagating through layer 0:\n",
      "Layer backward:\n",
      "  Grad output shape: (4, 3)\n",
      "  Activation gradient: [1. 0. 0.]... (first 3)\n",
      "  Grad z: [-0.01087178  0.          0.        ]... (first 3)\n",
      "  Grad weights shape: (2, 3)\n",
      "  Grad input: [-0.01716886 -0.00589859  0.05928329]... (first 3)\n",
      "\n",
      "Loss: 0.2535\n",
      "Predictions: [0.55447277 0.4621652  0.49782045 0.52771308]\n",
      "True values: [1. 1. 0. 0.]\n",
      "\n",
      "==================================================\n",
      "EPOCH 2\n",
      "==================================================\n",
      "=== FORWARD PASS ===\n",
      "Passing through layer 0:\n",
      "Layer forward:\n",
      "  Input shape: (4, 2)\n",
      "  Weights shape: (2, 3)\n",
      "  Z (before activation): [ 1.10807392 -0.16066062 -0.61861293]... (first 3 values)\n",
      "  A (after activation): [1.10807392 0.         0.        ]... (first 3 values)\n",
      "\n",
      "Passing through layer 1:\n",
      "Layer forward:\n",
      "  Input shape: (4, 3)\n",
      "  Weights shape: (3, 1)\n",
      "  Z (before activation): [ 0.22964585 -0.12386849 -0.00206681]... (first 3 values)\n",
      "  A (after activation): [0.55716048 0.46907241 0.4994833 ]... (first 3 values)\n",
      "\n",
      "Final output: [[0.55716048]\n",
      " [0.46907241]\n",
      " [0.4994833 ]\n",
      " [0.52901356]]\n",
      "\n",
      "=== BACKWARD PASS ===\n",
      "Initial loss gradient: [[-0.22141976]\n",
      " [-0.26546379]\n",
      " [ 0.24974165]\n",
      " [ 0.26450678]]\n",
      "\n",
      "Backpropagating through layer 1:\n",
      "Layer backward:\n",
      "  Grad output shape: (4, 1)\n",
      "  Activation gradient: [0.24673268 0.24904348 0.24999973]... (first 3)\n",
      "  Grad z: [-0.05463149 -0.06611203  0.06243535]... (first 3)\n",
      "  Grad weights shape: (3, 1)\n",
      "  Grad input: [-0.0113524   0.08525689  0.07694242]... (first 3)\n",
      "\n",
      "Backpropagating through layer 0:\n",
      "Layer backward:\n",
      "  Grad output shape: (4, 3)\n",
      "  Activation gradient: [1. 0. 0.]... (first 3)\n",
      "  Grad z: [-0.0113524  0.         0.       ]... (first 3)\n",
      "  Grad weights shape: (2, 3)\n",
      "  Grad input: [-0.01794041 -0.00616511  0.05683605]... (first 3)\n",
      "\n",
      "Loss: 0.2518\n",
      "Predictions: [0.55716048 0.46907241 0.4994833  0.52901356]\n",
      "True values: [1. 1. 0. 0.]\n",
      "\n",
      "==================================================\n",
      "EPOCH 3\n",
      "==================================================\n",
      "=== FORWARD PASS ===\n",
      "Passing through layer 0:\n",
      "Layer forward:\n",
      "  Input shape: (4, 2)\n",
      "  Weights shape: (2, 3)\n",
      "  Z (before activation): [ 1.1088342  -0.16792074 -0.61861293]... (first 3 values)\n",
      "  A (after activation): [1.1088342 0.        0.       ]... (first 3 values)\n",
      "\n",
      "Passing through layer 1:\n",
      "Layer forward:\n",
      "  Input shape: (4, 3)\n",
      "  Weights shape: (3, 1)\n",
      "  Z (before activation): [ 0.2402192  -0.09692734  0.00409695]... (first 3 values)\n",
      "  A (after activation): [0.55976767 0.47578712 0.50102424]... (first 3 values)\n",
      "\n",
      "Final output: [[0.55976767]\n",
      " [0.47578712]\n",
      " [0.50102424]\n",
      " [0.53025467]]\n",
      "\n",
      "=== BACKWARD PASS ===\n",
      "Initial loss gradient: [[-0.22011617]\n",
      " [-0.26210644]\n",
      " [ 0.25051212]\n",
      " [ 0.26512733]]\n",
      "\n",
      "Backpropagating through layer 1:\n",
      "Layer backward:\n",
      "  Grad output shape: (4, 1)\n",
      "  Activation gradient: [0.24642783 0.24941374 0.24999895]... (first 3)\n",
      "  Grad z: [-0.05424275 -0.06537295  0.06262777]... (first 3)\n",
      "  Grad weights shape: (3, 1)\n",
      "  Grad input: [-0.01181828  0.0845664   0.07639492]... (first 3)\n",
      "\n",
      "Backpropagating through layer 0:\n",
      "Layer backward:\n",
      "  Grad output shape: (4, 3)\n",
      "  Activation gradient: [1. 0. 0.]... (first 3)\n",
      "  Grad z: [-0.01181828  0.          0.        ]... (first 3)\n",
      "  Grad weights shape: (2, 3)\n",
      "  Grad input: [-0.01869023 -0.00642418  0.05445144]... (first 3)\n",
      "\n",
      "Loss: 0.2502\n",
      "Predictions: [0.55976767 0.47578712 0.50102424 0.53025467]\n",
      "True values: [1. 1. 0. 0.]\n",
      "\n",
      "==================================================\n",
      "ACTIVATION FUNCTION ANALYSIS\n",
      "==================================================\n",
      "Input values: [-2 -1  0  1  2]\n",
      "ReLU output: [0 0 0 1 2]\n",
      "ReLU gradient: [0. 0. 0. 1. 1.]\n",
      "\n",
      "Sigmoid output: [0.11920292 0.26894142 0.5        0.73105858 0.88079708]\n",
      "Sigmoid gradient: [0.10499359 0.19661193 0.25       0.19661193 0.10499359]\n",
      "\n",
      "Tanh output: [-0.96402758 -0.76159416  0.          0.76159416  0.96402758]\n",
      "Tanh gradient: [0.07065082 0.41997434 1.         0.41997434 0.07065082]\n",
      "\n",
      "==================================================\n",
      "KEY INSIGHTS\n",
      "==================================================\n",
      "1. Forward pass: Input → Linear transform (Wx + b) → Activation → Next layer\n",
      "2. Backward pass: Loss gradient flows backward through activation derivatives\n",
      "3. Weights update using gradient of loss w.r.t. weights\n",
      "4. Each layer stores intermediate values needed for backprop\n",
      "5. Activation functions introduce non-linearity and affect gradient flow\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage - let's solve a simple problem\n",
    "print(\"Creating a simple dataset...\")\n",
    "# XOR-like problem: if x1 + x2 > 1, output 1, else 0\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(4, 2)  # 4 samples, 2 features\n",
    "y = ((X[:, 0] + X[:, 1]) > 1).astype(float).reshape(-1, 1)  # Binary output\n",
    "\n",
    "print(\"Dataset:\")\n",
    "print(f\"X:\\n{X}\")\n",
    "print(f\"y: {y.flatten()}\")\n",
    "print()\n",
    "\n",
    "# Create a simple MLP: 2 → 3 → 1\n",
    "# Number of neurons: Input layer (2) → Hidden layer (3, ReLU) → Output layer (1, Sigmoid)\n",
    "mlp = MLP(layer_sizes=[2, 3, 1],activations=[ReLU(), Sigmoid()])\n",
    "\n",
    "print(\"Training for a few steps...\")\n",
    "losses = []\n",
    "\n",
    "for epoch in range(3):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"EPOCH {epoch + 1}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    loss, y_pred = mlp.train_step(X, y, learning_rate=0.1)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    print(f\"Loss: {loss:.4f}\")\n",
    "    print(f\"Predictions: {y_pred.flatten()}\")\n",
    "    print(f\"True values: {y.flatten()}\")\n",
    "\n",
    "# Show how activation functions affect the flow\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"ACTIVATION FUNCTION ANALYSIS\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Test different inputs to see activation behavior\n",
    "test_input = np.array([[-2, -1, 0, 1, 2]]).T\n",
    "\n",
    "relu = ReLU()\n",
    "sigmoid = Sigmoid()\n",
    "tanh = Tanh()\n",
    "\n",
    "print(\"Input values:\", test_input.flatten())\n",
    "print(\"ReLU output:\", relu.forward(test_input).flatten())\n",
    "print(\"ReLU gradient:\", relu.backward(test_input).flatten())\n",
    "print()\n",
    "print(\"Sigmoid output:\", sigmoid.forward(test_input).flatten())\n",
    "print(\"Sigmoid gradient:\", sigmoid.backward(test_input).flatten())\n",
    "print()\n",
    "print(\"Tanh output:\", tanh.forward(test_input).flatten())\n",
    "print(\"Tanh gradient:\", tanh.backward(test_input).flatten())\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(\"1. Forward pass: Input → Linear transform (Wx + b) → Activation → Next layer\")\n",
    "print(\"2. Backward pass: Loss gradient flows backward through activation derivatives\")\n",
    "print(\"3. Weights update using gradient of loss w.r.t. weights\")\n",
    "print(\"4. Each layer stores intermediate values needed for backprop\")\n",
    "print(\"5. Activation functions introduce non-linearity and affect gradient flow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011835c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1_downgraded",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
