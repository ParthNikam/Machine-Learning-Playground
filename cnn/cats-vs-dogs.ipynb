{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c01b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from shutil import copyfile\n",
    "from random import seed, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imread\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout, ReLU\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba55d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"data/cats-vs-dogs\"\n",
    "cats_path = base_path + \"/Cat\"\n",
    "dogs_path = base_path + \"/Dog\"\n",
    "\n",
    "# for all the images, get their file names and put them against their label folder in a dataframe df\n",
    "\n",
    "data = []\n",
    "for filename in os.listdir(cats_path):\n",
    "    data.append({\"filename\": cats_path + \"/\" + filename, \"label\": \"cat\"})\n",
    "for filename in os.listdir(dogs_path):\n",
    "    data.append({\"filename\": dogs_path + \"/\" + filename, \"label\": \"dog\"})\n",
    "\n",
    "# save the dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"data/cats-vs-dogs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeac158",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cats-vs-dogs.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5140e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(df['filename'][231])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ef945b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm, glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aded2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'dog':1, 'cat':0}\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "size = 128, 128\n",
    "\n",
    "# for image in filenames\n",
    "# load each image and push that blob to a list X\n",
    "# push the label to the list y\n",
    "for image_path in df['filename']:\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img = img.convert('RGB')\n",
    "        img = img.resize(size)\n",
    "        X.append(np.array(img))\n",
    "        y.append(labels[df['label'][df['filename'] == image_path].values[0]])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_arr = np.array(X)\n",
    "y_arr = np.array(y)\n",
    "\n",
    "# Save to a single compressed file\n",
    "np.savez_compressed('data/dataset.npz', features=X_arr, labels=y_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/dataset.npz')\n",
    "X = data['features']\n",
    "y = data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdc8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b2baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    # Block 1\n",
    "    Conv2D(32, (3,3), padding='same', input_shape=(128, 128, 3)),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    # Block 2\n",
    "    Conv2D(64, (3,3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    # Block 3\n",
    "    Conv2D(128, (3,3), padding='same'),\n",
    "    BatchNormalization(),\n",
    "    ReLU(),\n",
    "    MaxPooling2D((2,2)),\n",
    "\n",
    "    # Dense layers\n",
    "    Flatten(),\n",
    "    Dense(256),\n",
    "    ReLU(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, 'sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275984e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad32c3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Early Stopping (mandatory in practice)\n",
    "callback = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# ImageDataGenerator lets you quickly set up Python generators that can \n",
    "# automatically turn image files on disk into batches of preprocessed tensors\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Use .flow() for data already loaded in arrays (X_train, y_train)\n",
    "train_generator = train_datagen.flow(\n",
    "    X_train, y_train,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Use .flow() for validation data as well\n",
    "val_generator = val_datagen.flow(\n",
    "    X_test, y_test,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    # Use .n instead of .samples for NumpyArrayIterator\n",
    "    steps_per_epoch=train_generator.n // train_generator.batch_size, \n",
    "    epochs=5,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.n // val_generator.batch_size,\n",
    "    callbacks=[callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d1e7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
